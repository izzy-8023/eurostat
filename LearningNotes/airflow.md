
# ğŸ“˜ Apache Airflow 

> ç”¨äºæ„å»ºã€è°ƒåº¦å’Œç›‘æ§æ•°æ®å·¥ç¨‹å·¥ä½œæµçš„å¼€æºå¹³å°ã€‚

---

## ğŸ§  ç›®å½•

- [ğŸ“˜ Apache Airflow](#-apache-airflow)
  - [ğŸ§  ç›®å½•](#-ç›®å½•)
  - [Airflow æ˜¯ä»€ä¹ˆï¼Ÿ](#airflow-æ˜¯ä»€ä¹ˆ)
  - [æ ¸å¿ƒæ¦‚å¿µ](#æ ¸å¿ƒæ¦‚å¿µ)
    - [1. DAG (Directed Acyclic Graph)](#1-dag-directed-acyclic-graph)
    - [2. Task](#2-task)
    - [3. Operator](#3-operator)
    - [4. Scheduler](#4-scheduler)
    - [5. Webserver](#5-webserver)
    - [6. Metadata Database](#6-metadata-database)
  - [å®‰è£…ä¸ç¯å¢ƒé…ç½®](#å®‰è£…ä¸ç¯å¢ƒé…ç½®)
    - [å¿«é€Ÿå®‰è£…ï¼ˆæœ¬åœ°å¼€å‘ï¼‰](#å¿«é€Ÿå®‰è£…æœ¬åœ°å¼€å‘)
    - [è®¾ç½®ç¯å¢ƒå˜é‡](#è®¾ç½®ç¯å¢ƒå˜é‡)
  - [DAG æ–‡ä»¶ç»“æ„ä¸è¯­æ³•](#dag-æ–‡ä»¶ç»“æ„ä¸è¯­æ³•)
    - [ä¸€ä¸ªå…¸å‹ DAG æ–‡ä»¶](#ä¸€ä¸ªå…¸å‹-dag-æ–‡ä»¶)
  - [å¸¸è§ Operator ç”¨æ³•](#å¸¸è§-operator-ç”¨æ³•)
    - [PythonOperator](#pythonoperator)
    - [BashOperator](#bashoperator)
    - [BranchPythonOperator](#branchpythonoperator)
  - [ä»»åŠ¡ä¾èµ–ä¸æ‰§è¡Œæµç¨‹](#ä»»åŠ¡ä¾èµ–ä¸æ‰§è¡Œæµç¨‹)
  - [Airflow å‘½ä»¤å¤§å…¨](#airflow-å‘½ä»¤å¤§å…¨)
  - [è°ƒè¯•æŠ€å·§ä¸æ—¥å¿—æŸ¥çœ‹](#è°ƒè¯•æŠ€å·§ä¸æ—¥å¿—æŸ¥çœ‹)
  - [é«˜çº§åŠŸèƒ½](#é«˜çº§åŠŸèƒ½)
    - [1. Trigger Rules](#1-trigger-rules)
    - [2. TaskGroupï¼ˆä»»åŠ¡åˆ†ç»„ï¼‰](#2-taskgroupä»»åŠ¡åˆ†ç»„)
    - [3. Branchingï¼ˆåˆ†æ”¯ï¼‰](#3-branchingåˆ†æ”¯)
    - [4. XComï¼ˆä»»åŠ¡é—´é€šä¿¡ï¼‰](#4-xcomä»»åŠ¡é—´é€šä¿¡)
    - [5. SLAï¼ˆæœåŠ¡çº§åˆ«åè®®ï¼‰](#5-slaæœåŠ¡çº§åˆ«åè®®)
  - [ä¸ Docker/Azure çš„ç»“åˆ](#ä¸-dockerazure-çš„ç»“åˆ)
  - [å¸¸è§é—®é¢˜æ’æŸ¥](#å¸¸è§é—®é¢˜æ’æŸ¥)

---

## Airflow æ˜¯ä»€ä¹ˆï¼Ÿ

Apache Airflow æ˜¯ä¸€ä¸ª **ç¼–æ’å·¥å…·**ï¼Œç”¨äºè®¾è®¡ã€è°ƒåº¦å’Œç›‘æ§æ•°æ®ç®¡é“ã€‚

* æ”¯æŒ Python ç¼–å†™çš„å·¥ä½œæµè„šæœ¬
* åŸç”Ÿæ”¯æŒå®šæ—¶è°ƒåº¦ã€ä¾èµ–ç®¡ç†ã€é‡è¯•æœºåˆ¶ã€ç›‘æ§
* å¯æ‰©å±•ï¼Œæ”¯æŒæ’ä»¶ã€è‡ªå®šä¹‰ Operator
* UI ç›‘æ§ç•Œé¢æ¸…æ™°ç›´è§‚

---

## æ ¸å¿ƒæ¦‚å¿µ

### 1. DAG (Directed Acyclic Graph)

* æœ‰å‘æ— ç¯å›¾ï¼Œæ˜¯ Airflow çš„åŸºæœ¬å•å…ƒ
* å®šä¹‰ä»»åŠ¡ä¹‹é—´çš„æ‰§è¡Œé¡ºåº
* ä¸æ‰§è¡Œä»»åŠ¡ï¼Œåªå®šä¹‰ç»“æ„
* ç”¨ Python è„šæœ¬è¡¨ç¤ºï¼Œå¿…é¡»ä¿å­˜åœ¨ `$AIRFLOW_HOME/dags/` ç›®å½•ä¸­

```python
from airflow import DAG
from datetime import datetime

dag = DAG(
    dag_id="example_dag",
    start_date=datetime(2024, 1, 1),
    schedule_interval="@daily",
    catchup=False
)
```

### 2. Task

* DAG ä¸­çš„æ¯ä¸ªèŠ‚ç‚¹å°±æ˜¯ä¸€ä¸ª Task
* æ¯ä¸ª Task æ˜¯ Operator çš„ä¸€ä¸ªå®ä¾‹

### 3. Operator

Operator æ˜¯ Task çš„æ¨¡æ¿ï¼š

| ç±»å‹                     | æè¿°           |
| ---------------------- | ------------ |
| `PythonOperator`       | æ‰§è¡Œ Python å‡½æ•° |
| `BashOperator`         | æ‰§è¡Œ Bash å‘½ä»¤   |
| `EmailOperator`        | å‘é€é‚®ä»¶         |
| `DummyOperator`        | å ä½ç¬¦          |
| `BranchPythonOperator` | æ¡ä»¶åˆ†æ”¯         |
| `DockerOperator`       | æ‰§è¡Œ Docker å®¹å™¨ |
| `PostgresOperator`     | æ‰§è¡Œ SQL       |

### 4. Scheduler

* ä¸æ–­æ‰«æ DAGsï¼Œå¹¶æ ¹æ® schedule\_interval æ‰§è¡Œä»»åŠ¡
* æ˜¯ Airflow çš„â€œå¤§è„‘â€

### 5. Webserver

* æä¾›å¯è§†åŒ–ç•Œé¢ï¼ŒæŸ¥çœ‹ DAG çŠ¶æ€ã€è§¦å‘è¿è¡Œã€æŸ¥çœ‹æ—¥å¿—ç­‰

### 6. Metadata Database

* å­˜å‚¨ DAG çš„çŠ¶æ€ã€ä»»åŠ¡æ‰§è¡Œç»“æœã€æ—¥å¿—ç­‰å…ƒä¿¡æ¯
* é»˜è®¤ä½¿ç”¨ SQLiteï¼ˆç”Ÿäº§å»ºè®®ä½¿ç”¨ PostgreSQL æˆ– MySQLï¼‰

---

## å®‰è£…ä¸ç¯å¢ƒé…ç½®

### å¿«é€Ÿå®‰è£…ï¼ˆæœ¬åœ°å¼€å‘ï¼‰

```bash
# å»ºè®®ä½¿ç”¨ Python 3.8+
pip install apache-airflow==2.8.1 --constraint "https://raw.githubusercontent.com/apache/airflow/constraints-2.8.1/constraints-3.8.txt"
```

æˆ–ä½¿ç”¨ Dockerï¼š

```bash
git clone https://github.com/apache/airflow.git
cd airflow
docker-compose up airflow-init
docker-compose up
```

### è®¾ç½®ç¯å¢ƒå˜é‡

```bash
export AIRFLOW_HOME=~/airflow
airflow db init
airflow users create \
    --username admin \
    --firstname Admin \
    --lastname User \
    --role Admin \
    --email admin@example.com \
    --password admin
```

---

## DAG æ–‡ä»¶ç»“æ„ä¸è¯­æ³•

### ä¸€ä¸ªå…¸å‹ DAG æ–‡ä»¶

```python
from airflow import DAG
from airflow.operators.bash import BashOperator
from datetime import datetime

with DAG(
    "my_dag",
    schedule_interval="@daily",
    start_date=datetime(2024, 1, 1),
    catchup=False,
    tags=["example"]
) as dag:

    task1 = BashOperator(
        task_id="say_hello",
        bash_command="echo 'Hello Airflow!'"
    )

    task2 = BashOperator(
        task_id="say_goodbye",
        bash_command="echo 'Goodbye!'"
    )

    task1 >> task2  # task1 å…ˆæ‰§è¡Œï¼Œç„¶åæ˜¯ task2
```

---

## å¸¸è§ Operator ç”¨æ³•

### PythonOperator

```python
from airflow.operators.python import PythonOperator

def my_function():
    print("Running Python Task")

task = PythonOperator(
    task_id="python_task",
    python_callable=my_function
)
```

### BashOperator

```python
BashOperator(
    task_id="list_files",
    bash_command="ls -l /"
)
```

### BranchPythonOperator

```python
from airflow.operators.python import BranchPythonOperator

def choose_branch():
    return "task_a" if datetime.now().day % 2 == 0 else "task_b"

branch_task = BranchPythonOperator(
    task_id='branching',
    python_callable=choose_branch
)
```

---

## ä»»åŠ¡ä¾èµ–ä¸æ‰§è¡Œæµç¨‹

```python
t1 >> t2  # t1 å…ˆæ‰§è¡Œï¼Œå†æ‰§è¡Œ t2
t2.set_upstream(t1)
t1.set_downstream(t2)

# å¤šä»»åŠ¡ä¾èµ–
[t1, t2] >> t3  # t3 è¦ç­‰ t1 å’Œ t2 éƒ½å®Œæˆ
```

---

## Airflow å‘½ä»¤å¤§å…¨

| å‘½ä»¤                                                 | ä½œç”¨                   |
| -------------------------------------------------- | -------------------- |
| `airflow db init`                                  | åˆå§‹åŒ–æ•°æ®åº“               |
| `airflow webserver`                                | å¯åŠ¨ Web UIï¼ˆé»˜è®¤ç«¯å£ 8080ï¼‰ |
| `airflow scheduler`                                | å¯åŠ¨è°ƒåº¦å™¨                |
| `airflow dags list`                                | æŸ¥çœ‹æ‰€æœ‰ DAG             |
| `airflow tasks list dag_id`                        | æŸ¥çœ‹æŸä¸ª DAG ä¸­çš„ä»»åŠ¡        |
| `airflow tasks test dag_id task_id execution_date` | æµ‹è¯•å•ä¸ªä»»åŠ¡ï¼ˆä¸è®°å½•æ•°æ®åº“ï¼‰       |

---

## è°ƒè¯•æŠ€å·§ä¸æ—¥å¿—æŸ¥çœ‹

* Web UI ä¸­ç‚¹å‡» DAG â†’ ç‚¹å‡» Task æŸ¥çœ‹æ—¥å¿—
* æ—¥å¿—è·¯å¾„ï¼š`$AIRFLOW_HOME/logs/`
* ä½¿ç”¨ `airflow tasks test` æ¥éªŒè¯ PythonOperator å‡½æ•°æ˜¯å¦æ­£å¸¸

---

## é«˜çº§åŠŸèƒ½

### 1. Trigger Rules

æ§åˆ¶ä»»åŠ¡æ˜¯å¦æ‰§è¡Œçš„ç­–ç•¥ï¼š

```python
trigger_rule="all_success"  # é»˜è®¤å€¼
trigger_rule="all_failed"
trigger_rule="one_success"
trigger_rule="none_failed"
```

### 2. TaskGroupï¼ˆä»»åŠ¡åˆ†ç»„ï¼‰

```python
from airflow.utils.task_group import TaskGroup

with TaskGroup("etl_tasks") as etl:
    extract = BashOperator(...)
    transform = BashOperator(...)
    load = BashOperator(...)

etl >> another_task
```

### 3. Branchingï¼ˆåˆ†æ”¯ï¼‰

* ä½¿ç”¨ `BranchPythonOperator` å®ç°æ¡ä»¶é€»è¾‘

### 4. XComï¼ˆä»»åŠ¡é—´é€šä¿¡ï¼‰

```python
# æ¨é€
task_instance.xcom_push(key='value', value=123)

# æ‹‰å–
task_instance.xcom_pull(task_ids='my_task', key='value')
```

### 5. SLAï¼ˆæœåŠ¡çº§åˆ«åè®®ï¼‰

```python
DAG(
    dag_id="example_sla",
    sla_miss_callback=notify_func,
    ...
)

PythonOperator(
    task_id='slow_task',
    python_callable=slow_func,
    sla=timedelta(minutes=5)
)
```

---

## ä¸ Docker/Azure çš„ç»“åˆ

* å¯ç”¨ Docker Compose å¿«é€Ÿæ­å»ºæœ¬åœ°å¼€å‘ç¯å¢ƒ
* Azure æä¾› Airflow æ‰˜ç®¡æœåŠ¡ï¼ˆä¾‹å¦‚é€šè¿‡ Azure Data Factory è§¦å‘ï¼‰
* å¯é€šè¿‡ Azure Container Instances / Kubernetes + Helm éƒ¨ç½²ç”Ÿäº§ç¯å¢ƒ

---

## å¸¸è§é—®é¢˜æ’æŸ¥

| é—®é¢˜          | åŸå›                   | è§£å†³æ–¹æ¡ˆ                           |
| ----------- | ------------------- | ------------------------------ |
| DAG æ— æ³•è¯†åˆ«    | Python æ–‡ä»¶æœ‰è¯­æ³•é”™è¯¯      | è¿è¡Œ `python my_dag.py` çœ‹æ˜¯å¦æŠ¥é”™    |
| ä»»åŠ¡å¡ä½ä¸åŠ¨      | Scheduler æ²¡æœ‰å¯åŠ¨æˆ–èµ„æºä¸è¶³ | ç¡®ä¿ `airflow scheduler` æ­£å¸¸è¿è¡Œ    |
| æ—¥å¿—æ— æ³•æŸ¥çœ‹      | æ²¡æœ‰é…ç½®æ—¥å¿—è·¯å¾„            | é…ç½® `airflow.cfg` ä¸­çš„ logging è®¾ç½® |
| Web UI ç™»é™†å¤±è´¥ | ç”¨æˆ·æ²¡åˆ›å»ºæˆ–å¯†ç é”™è¯¯          | ä½¿ç”¨ `airflow users create` åˆ›å»ºè´¦æˆ· |

---

