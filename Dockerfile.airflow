# Enhanced Eurostat Airflow Dockerfile - OPTIMIZED FOR FAST BUILDS
# Optimized for the cleaned-up project with enhanced DAG and shared modules

FROM apache/airflow:3.0.1

# Set the USER to root temporarily to install system dependencies
USER root

# Install additional system dependencies
RUN apt-get update \
    && apt-get install -y --no-install-recommends \
        postgresql-client \
        curl \
    && apt-get autoremove -yqq --purge \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# Make cleanup script executable
COPY scripts/cleanup_sql_files.sh /opt/airflow/scripts/
RUN chmod +x /opt/airflow/scripts/cleanup_sql_files.sh

# Create entrypoint script
RUN echo '#!/bin/bash\n\
/opt/airflow/scripts/cleanup_sql_files.sh\n\
exec "$@"' > /opt/airflow/entrypoint.sh \
    && chmod +x /opt/airflow/entrypoint.sh

# Switch back to airflow user
USER airflow

# Set entrypoint
ENTRYPOINT ["/opt/airflow/entrypoint.sh"]
CMD ["airflow", "standalone"]

# OPTIMIZATION: Copy requirements FIRST for better layer caching
# This layer will only rebuild if requirements change
COPY requirements-airflow.txt /requirements.txt

# OPTIMIZATION: Install dependencies from requirements file
# Use Flask 3.x compatible versions of all dependencies
RUN pip install --no-cache-dir -r /requirements.txt

# OPTIMIZATION: Install Airflow providers separately (they're often already included)
RUN pip install --no-cache-dir --no-deps \
    apache-airflow-providers-postgres>=5.0.0 \
    apache-airflow-providers-common-sql>=1.0.0 \
    || echo "Providers already included in base image"

# Set Python path EARLY for better caching
ENV PYTHONPATH="${PYTHONPATH}:/opt/airflow/scripts:/opt/airflow/scripts/shared"

# Set environment variables for enhanced pipeline (cached layer)
ENV ENHANCED_PIPELINE_MODE=true
ENV USE_SHARED_MODULES=true
ENV AIRFLOW_VAR_USE_SHARED_HEALTH_DATASETS=true
ENV AIRFLOW_VAR_ENHANCED_BATCH_SIZE=2000
ENV AIRFLOW_VAR_ENABLE_STREAMING_LOAD=true

# Create necessary directories (cached layer)
RUN mkdir -p \
    /opt/airflow/temp_enhanced_downloads \
    /opt/airflow/logs/enhanced_pipeline \
    /opt/airflow/data_cache

# OPTIMIZATION: Copy scripts LAST (most frequently changed)
# This ensures script changes don't invalidate dependency cache
COPY ./scripts/ /opt/airflow/scripts/

# The enhanced DAG will be mounted via volumes in docker-compose-airflow.yaml
